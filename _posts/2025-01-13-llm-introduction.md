---
title: "LLM个人笔记"
date: 2025-01-13 10:00:00 +0800
categories: [技术探索, 人工智能]
tags: [LLM, AI]
---

## 写在前面

最近一两年，AI 这个词火得不行，尤其是 ChatGPT 横空出世之后，身边的朋友都在讨论"大模型"、"LLM"这些概念。作为一个技术人，我也花了不少时间去了解和使用这些工具。

---

## 一、LLM 到底是啥

### 先说说名字

**LLM** 全称是 **Large Language Model**，翻译过来就是"大语言模型"。

这名字听起来挺唬人，其实拆开来看就好理解了：

- **Large（大）**：模型参数量巨大，动辄几十亿、上百亿个参数
- **Language（语言）**：专门处理人类语言的
- **Model（模型）**：就是一个数学模型，通过训练学会了某种能力

### 用人话说就是

想象一下，你有个特别博学的朋友，他读过海量的书籍、文章、对话记录。当你问他问题时，他能根据之前看过的内容，给你一个看起来很靠谱的回答。

LLM 就是这么个东西，只不过它"读过"的内容比任何人都多得多，而且"记忆力"也强得多。

### 它能干啥？

说白了，LLM 就是个"文字处理专家"，能做的事情包括但不限于：

- **聊天对话**：像 ChatGPT 那样，能跟你一来一回地聊天
- **写文章**：帮你写邮件、报告、文案，甚至写代码
- **翻译**：把中文翻译成英文，或者其他语言
- **总结归纳**：把一大段文字提炼成几句话
- **回答问题**：像个百科全书一样回答各种问题
- **代码辅助**：帮程序员写代码、找 bug、解释代码逻辑

---

## 二、LLM 的优点和缺点

### 先说说优点

#### 1. 知识面广得离谱

LLM 训练时"看过"的内容涵盖了互联网上的大量文本，从科技、历史、文学到编程、医学，几乎无所不包。

你问它问题，大概率能给你一个还算靠谱的答案。这比自己去搜索引擎翻半天资料要快多了。

#### 2. 24 小时随叫随到

不像人类助手，LLM 不需要休息，不会请假，也不会因为心情不好而敷衍你。

半夜三点突然想到个问题？没关系，它随时在线。

#### 3. 效率高到吓人

写个邮件、整理个会议纪要、生成个代码模板，这些事情对 LLM 来说就是秒秒钟的事。

以前可能要花半小时的工作，现在几分钟就搞定了。

#### 4. 不会嫌你问题傻

有些问题你可能不好意思问同事或者老师，怕被笑话。但问 LLM 就没这个顾虑，它不会评判你，只会尽力回答。

#### 5. 能举一反三

给它一个例子，它能生成类似的多个变体。比如你给它一个邮件模板，它能根据不同场景生成不同版本。

---

### 再说说缺点

#### 1. 会一本正经地胡说八道

这是 LLM 最大的问题。它有时候会非常自信地给你一个错误答案，而且说得跟真的一样。

比如你问它某个历史事件的日期，它可能会编造一个看起来很合理的日期，但实际上是错的。

**这个现象有个专业术语叫"幻觉"（Hallucination）**。

#### 2. 没有真正的理解能力

LLM 本质上是在做"文字接龙"，根据概率预测下一个词应该是什么。它并不真正"理解"内容的含义。

就像鹦鹉学舌，说得再像，也不代表它真懂。

#### 3. 知识有时效性

LLM 的知识来自训练数据，而训练数据是有截止日期的。

比如 GPT-3.5 的知识截止到 2021 年 9 月，你问它 2022 年发生的事情，它就不知道了。

#### 4. 容易被"带偏"

如果你在对话中给它一些错误信息，它可能会基于这些错误信息继续回答，而不会质疑你。

#### 5. 缺乏常识和判断力

LLM 在处理一些需要常识或者道德判断的问题时，可能会给出不合适的答案。

比如你问它"怎么伤害别人"，早期的模型可能真的会给你一些建议（当然现在都加了安全限制）。

#### 6. 成本不低

训练一个大模型需要海量的计算资源和电力，成本高得吓人。使用 API 也是按调用次数收费的，用多了也是一笔不小的开支。

---

## 三、使用 LLM 常见的坑

### 1. 过度依赖，不加验证

**问题**：直接把 LLM 的回答当成标准答案，不做任何验证。

**后果**：可能会被错误信息误导，尤其是在专业领域。

**建议**：
- 把 LLM 当成"助手"而不是"专家"
- 重要信息一定要交叉验证
- 涉及专业领域的问题，最好咨询真正的专家

---

### 2. 提问不清晰

**问题**：问题描述模糊，导致 LLM 理解偏差。

**例子**：
- ❌ "帮我写个代码"（太笼统）
- ✅ "帮我用 Python 写一个函数，输入是一个整数列表，输出是列表中的最大值"

**建议**：
- 提供足够的上下文
- 说清楚你的需求和期望
- 必要时给出示例

---

### 3. 把 LLM 当搜索引擎用

**问题**：问一些需要实时信息或者精确数据的问题。

**例子**：
- "今天天气怎么样？"
- "某某股票现在多少钱？"
- "最新的 iPhone 价格是多少？"

**建议**：
- 这类问题还是用搜索引擎或者专门的工具
- LLM 更适合回答概念性、分析性的问题

---

### 4. 期望它能做所有事

**问题**：以为 LLM 是万能的，什么都能做。

**现实**：
- 它不能访问互联网（除非特别配置）
- 它不能执行真正的代码（只能生成代码）
- 它不能处理图片、视频（除非是多模态模型）
- 它不能帮你做决策（只能提供参考）

**建议**：
- 了解 LLM 的能力边界
- 选择合适的工具做合适的事

---

### 5. 忽视隐私和安全

**问题**：把敏感信息直接输入给 LLM。

**风险**：
- 你的输入可能会被用于训练
- 敏感信息可能会泄露
- 商业机密可能会被窃取

**建议**：
- 不要输入个人隐私信息（身份证号、密码等）
- 不要输入公司机密
- 使用企业版或者私有部署的模型

---

### 6. 不会追问和引导

**问题**：得到一个不满意的答案就放弃了。

**技巧**：
- 如果答案不满意，可以追问："能再详细一点吗？"
- 可以换个角度问："从另一个角度来看呢？"
- 可以给出反馈："这个答案不太对，应该是..."

**建议**：
- 把对话当成一个迭代的过程
- 多轮对话往往能得到更好的结果

---

### 7. 代码直接复制粘贴

**问题**：LLM 生成的代码直接拿来用，不做任何检查。

**风险**：
- 代码可能有 bug
- 代码可能不符合你的实际需求
- 代码可能有安全漏洞

**建议**：
- 仔细阅读生成的代码
- 理解代码的逻辑
- 测试代码是否正确
- 根据实际情况调整

---

### 8. 忽视版权问题

**问题**：直接使用 LLM 生成的内容，不考虑版权。

**风险**：
- 生成的内容可能侵犯他人版权
- 商业使用可能有法律风险

**建议**：
- 了解使用条款
- 重要内容最好人工审核和修改
- 商业用途要特别谨慎

---

## 四、我的一些使用心得

### 1. 把它当成"初稿生成器"

我现在写文章、写代码，经常先让 LLM 生成一个初稿，然后我再基于这个初稿进行修改和完善。

这样效率高很多，而且不容易有"空白页焦虑"。

### 2. 用它来学习新知识

遇到不懂的概念，我会先问 LLM，让它用简单的语言解释。

然后再去查资料深入学习。这样能快速建立一个初步的认知框架。

### 3. 让它帮我整理思路

有时候脑子里有很多想法，但是比较乱。我会把这些想法告诉 LLM，让它帮我整理成条理清晰的大纲。

### 4. 用它来做头脑风暴

需要创意的时候，我会让 LLM 给我提供一些思路。

虽然不一定都能用，但往往能激发我自己的灵感。

### 5. 把它当成"橡皮鸭"

程序员都知道"橡皮鸭调试法"——把问题讲给橡皮鸭听，往往就能想明白。

LLM 就是个很好的"橡皮鸭"，而且它还能给你反馈。

---

## 五、写在最后

LLM 确实是个很强大的工具，但它终究只是工具。

**它不能替代人的思考和判断，但可以大大提高我们的效率。**

用好它的关键是：
- 了解它的能力和局限
- 保持批判性思维
- 把它当成助手而不是老师
- 不断学习和适应

技术在进步，LLM 也在不断进化。也许未来它会变得更强大、更可靠。

但无论如何，**保持学习、保持思考，这才是最重要的。**
